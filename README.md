# ğŸ“š LangChain RAG with Local LLM (Ollama) & ChromaDB

This project demonstrates a **Retrieval-Augmented Generation (RAG)** pipeline using:

- ğŸ’¬ Local LLMs served via [Ollama](https://ollama.com/)
- ğŸ” ChromaDB for local vector storage
- ğŸ§  HuggingFace embeddings (`all-MiniLM-L6-v2`)
- âš™ï¸ LangChain to orchestrate the components

---

## ğŸ§± Project Structure

```bash
LANGCHAIN-RAG/
â”œâ”€â”€ data/                # Input `.md` (Markdown) files go here
â”œâ”€â”€ create_database.py   # Embeds data and populates ChromaDB
â”œâ”€â”€ query_data.py        # Script to ask questions
â”œâ”€â”€ requirements.txt     # Project dependencies
â””â”€â”€ README.md            # Project documentation


ğŸš€ Getting Started
1. Start the Ollama server
Make sure Ollama is installed and running locally:
ollama serve

2. Pull a language model (e.g., LLaMA 3)
ollama run llama3
This ensures the model is available for inference.

3. Install dependencies
We recommend using a virtual environment:
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt

4. Prepare your data
Place your .md files in the data/ folder. For example:

data/
â”œâ”€â”€ alice_in_wonderland.md
Then run:
python create_database.py
This will embed the Markdown files and store them in ChromaDB locally.

5. Ask questions
python query_data.py "Who is the White Rabbit?"
Youâ€™ll get answers based only on the context in your Markdown files.

ğŸ“¦ Dependencies (requirements.txt)

python-dotenv==1.0.1
langchain==0.2.2
langchain-community==0.2.3
langchain-openai==0.1.8
unstructured==0.14.4
chromadb==0.5.0
openai==1.31.1
tiktoken==0.7.0

## ğŸ–¼ï¸ Demo

![Screenshot of RAG pipeline](assets/screenshot.png)


ğŸ“Œ Notes
Works completely offline with local models (no OpenAI API required).

Uses all-MiniLM-L6-v2 for embedding via HuggingFace.

You can extend it to support PDFs, DOCX, or other file types using LangChainâ€™s unstructured loader.

The vector DB is persisted under the default Chroma path (./chroma/ or similar).

